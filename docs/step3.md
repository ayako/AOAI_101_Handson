# Azure OpenAI に自前のドキュメントを組み込む
## 前提知識
### add your data 機能について軽く解説
GPT の回答はあくまでも GPT が知り得る範囲の情報から尤もらしい答えを応答しているに過ぎないことは周知の事実かと思います。
従って、GPT に最新のデータや業務データ等の外部に公開されていないデータを考慮した回答をしてほしい場合には、何らかの方法で GPT にそれらの情報をコンテキストとして教える必要があります。

Azure OpenAI 独自の機能である、"add your data" 機能はそのシンプルなアプローチの一つです。
この機能を使うことで、簡単に自前のデータを GPT に接続し、GPT が本来知りえなかった情報を根拠にした結果を得ることが可能になります。

### add your data 機能の日本語対応状況について
この便利そうに見える on your data 機能ですが、残念ながらまだ開発中の機能のため、日本語に正式に対応していません。
そのため、一番シンプルな、OpenAI Playground からデータを追加する方法で実施した場合、内部的に使われる Cognitive Search のインデックスが英語設定になってしまったりして、意図通りの結果を得られません。

そのうち開発が進めばこの点も改善することと思いますが、いまのところはもう少し手の込んだ方法でデータを足してやる必要があります。
具体的な手順についてはこの後で説明します。

### いまのところやらなければいけないこと
いまのところ実施しなければいけないことは以下の 2 点です。

- 入力のドキュメントを適切な形でチャンク分けする
- Cognitive Search のインデックスを日本語で作成する

これらの作業から、追加データのチャンキングの大切さや Cognitive Search の使いかたなど、OpenAI にデータを繋ぐうえで大切なポイントについてもご理解いただけたら幸いです。


## on your data を試してみる
### on your data で利用するデータについて
on your data で利用するデータについては、自前でインデックスを作る場合、最終的にテキスト形式に落とし込めればどんな形式でも問題ありません。
（今回のハンズオンについては、講師がサンプルデータを提供します）

### Azure Cognitive Search を作る
まずは、追加するデータを検索可能にするために、[Cognitive Search](https://learn.microsoft.com/ja-jp/azure/search/search-what-is-azure-search) というリソースを作ります。
Azure Cognitive Search は、Web、モバイル、エンタープライズ アプリケーションに、プライベートで異種のコンテンツに対するリッチな検索エクスペリエンスを組み込むためのインフラストラクチャ、API、およびツールを開発者に提供するクラウド検索サービスです。

Cognitive Search を作成するには、まずは [Azure Portal](https://portal.azure.com) のトップページから、「リソースの作成」を行います。

![Create Cognitive Search](./img/CreateCogSearch001.png)

Azure OpenAI を作ったときと同じように、マーケットプレースで "Cognitive Search" と検索し、Cognitive Search の「作成」を開始します。

![Cognitive Search の作成](./img/CreateCogSearch002.png)

基本設定画面では、以下の様に情報を入力します。

- サブスクリプション : Azure OpenAI と同じサブスクリプション
- リソースグループ : 任意の名前
  - Azure OpenAI と同じ名前のリソースグループに入れておくと、あと片付けが一発で終わるのでおススメです。
- サービス名 : 任意のサービス名
- 場所 : Japan East など利用する場所から近いリージョンを選択
- 価格レベル : Standard

> サービス名については、今後の作業で使いますので、どこかにメモをしておきましょう

![Cognitive Search の基本設定](./img/CreateCogSearch003.png)

入力が終わったら「確認及び作成」ボタンを押して、最終確認画面に遷移します。
ここでデプロイ内容の確認が終わったら「作成」ボタンをクリックして Cognitive Search を作成します。

Cognitive Search のデプロイが完了したら、プログラムから Cognitive Search へアクセスするためのキーの情報を取得しましょう。
以下の画面の通り、作成した Cognitive Search の管理画面に Azure Portal にて移動し、左ペインの「キー」をクリックして開きます。

![Cognitive Search Key](./img/CreateCogSearch004.png)

画面内の「プライマリ管理者キー」もしくは「セカンダリ管理者キー」のいずれかのパスワードが隠された形になっているテキストボックスの右端にあるコピーボタンをクリックして内容をコピーします。
画面上は隠れていますが、別のテキストエディタなどにペーストすると、きちんとキーが取得できていることがわかると思います。

こちらのキーについても、今後使いますのでどこかにメモをしておきましょう。

!> このキーと Cognitive Search 名の組み合わせが外部に流出すると、意図せず悪用される原因になりますので、Git のリポジトリ等に Push したり、外部公開しないようにご注意ください！

### 入力するドキュメントをチャンク分けする
ここが、ChatGPT が長文の参考文献を利用する際に重要な要素となります。なぜ適切なチャンク分けが必要かというと、ChatGPT などの LLM は、利用できるトークン数の範囲内でしか In-Context な学習を行えないためです。

- あまりにも長い文章を学習データとして与えると、学習データだけで利用できるトークン数を超過してしまう。
- 一方、チャンクを適当に切ると、含めるべき文章が全て含まれない形の文章の断片がコンテキストに含まれなくなってしまう。

従って、チャンク分割を適切に実施することで、LLM が利用できるトークン数の範囲内で、充分にコンテキストに知識を与えることが大切なわけです。

チャンク分けをするアプローチは色々あって、ここが実はエンジニアの腕の見せ所でもあります。
例えば意味段落ごとにチャンクを作ったり、隣り合った似た知識をオーバーラップさせる形でチャンクを切ったり、と工夫が色々と出来るポイントです。
ただ、今回はハンズオンの時間に限りもあり、あまり長時間かけられないため、入力された文章を指定したトークン上限を超えない範囲で機械的に切るアプローチで進めます。

自動チャンク分け用のスクリプトについては、[以下のリポジトリ](https://github.com/tokawa-ms/AOAI_101_ChunkingScript_Python)に公開してありますので、ローカルにダウンロードして任意のディレクトリに展開ください。

AOAI_101_ChunkingScript_Python
https://github.com/tokawa-ms/AOAI_101_ChunkingScript_Python

ダウンロードが完了しましたら、チャンク分けするデータならびに出力先のディレクトリの作成を行います。
先ほどダウンロードして展開したサンプルコードに、必要なディレクトリの作成用スクリプトも含めてあります。
先ほどダウンロードしたファイルのあるフォルダでターミナルを開くか、VSCode を開いて、コンソールから以下のスクリプトを実行してください。

```bat
> python ./initdir.py
```

スクリプトの実行結果として作成された data フォルダに、チャンク分け対象となるドキュメントを入れてください。

ここまでの準備が終わりましたら、チャンク分けスクリプトの存在するフォルダまで戻り、以下のコマンドを実行しましょう。

```bat
> python ./autochunk.py
```

エラーなく動作した場合、先ほど作った ./data/output フォルダの中に、チャンク分けされたテキストファイルが複数個存在しているはずです。

きちんとデータがチャンク分けされていることを確認したら、今度はインデックス登録用のデータフレームに変換します。
ここもサンプルコードを提供していますので、以下のコマンドを実行してみましょう。

```bat
> python ./createdataframe.py
```

このスクリプトを実行し終わると、"chunked_dataset.json" というファイルが、スクリプトと同じ階層に出来ているはずです。
このファイルは、テキストエディタで開いていただくと分かる通り、先ほどチャンク分けしたデータを一括登録できるように JSON にまとめ、また ID やファイル名などの今後 on your Data の機能で使うのに必要なレコードを追加したものになっています。

### Cognitive Search に日本語のインデックスを作る
ここまで来たら、あとは Cognitive Search に日本語のインデックスを登録するだけです。
この部分も同様に、サンプルスクリプトを提供していますので、先ほどチャンク分けをしたディレクトリで作業を進めます。

まずは、Cognitive Search への接続情報を環境変数へ格納します。
（本来であればシークレットストアなど使うべきなのですが、今回は簡単に進めるために便宜上簡易な手段を使っております。）

以下の内容で環境変数を登録ください

|  環境変数名  |  値  |
|  ----  |  ---- |
|  SEARCH_SERVICE_NAME  |  先ほどメモした Cognitive Search の名前  |
|  SEARCH_API_KEY  |  先ほどメモした Cognitive Search のアクセスキー  |
|  SEARCH_INDEX_NAME  |  作成するインデックスの名前（任意でここでつけていただいて OK です）  |

環境変数への登録方法は、OS によってまちまちかと思いますが、各自自身の利用している環境にあわせてセットアップしてください。

例えば、Windows PowerShell 環境だと以下のような構文になります。

```powershell
$env:SEARCH_SERVICE_NAME="CognitiveSearch名"
$env:SEARCH_INDEX_NAME="インデックス名"
$env:SEARCH_API_KEY="キーの情報"

Get-ChildItem env:
```
>! PowerShell の場合、登録する名前やキーなどの文字列はダブルクォーテーションで囲む必要があります

環境変数の登録が終わりましたら、実際にスクリプトを流してインデックスの登録を行います。

```bat
> python ./addindex.py
```

> インデックスの登録には多少時間がかかる場合がありますので、この後の作業を進める前にコーヒーでも一杯飲んできましょう

Azure Portal に移動して、インデックスを作成した Cognitive Search の情報を確認します。

Cognitive Search の画面に移動したら、左ペインより「インデックス」を選択し、開いたインデックスのリストから先ほど作成したインデックスを選択して更に開きます。

すると、下記の様な画面が開きますので、「ドキュメント」の所の値が 0　ではないことを確認しましょう。

![Index](./img/Indexing002.png)

また、この画面の「クエリ文字列」にドキュメント内に含まれている単語を入れて「検索」をすることで、ドキュメントが検索にかかることも確認できますので、念のためやっておきましょう。

![検索結果](./img/indexing003.png)

ここで検索までうまく行ったら、日本語インデックスの作成は完了です！

### 出来たインデックスを Azure OpenAI Studio から接続する
on your data で接続する。

### 試してみる
まずは Playground で試してみる。

### 企業向け GPT のサンプルをデプロイしてみる
WebApp をデプロイしてみる。